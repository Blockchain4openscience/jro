{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Global optimization is an algorithmic need that is ubiquitous throughout the natural sciences, engineering, and other technical spheres.  It is a non-trivial task, particularly when the function to be optimized has many local minima and the optimization algorithm may get trapped in the local minima of the function to be optimized.  For that reason, many competing approaches have been proposed for global optimization, especially those inspired by nature.  The goal of the library proposed here is to develop a user-friendly framework in C++11 (with wrappers for Python) that can be used to successfully and efficiently carry out global optimization of challenging cost functions with minimum expertise required.\n",
    "\n",
    "CEGO (C++11 Evolutionary Global Optimization) is a C++11-based optimization library that minimizes an arbitrary cost function.  In C++, the cost function to be minimized is of type ``std::function<double(const CEGO::AbstractIndividual *)>``, where ``CEGO::AbstractIndividual`` is the base class for an individual in the population of candidate solutions.  The independent variables to be optimized are of type ``std::vector<CEGO::numberish>``, where the datatype ``CEGO::numberish`` can accept both discrete (integer) and continuous values.\n",
    "\n",
    "A brief summary of the functionality of CEGO includes:\n",
    "\n",
    "* The implementation of the ALPS algorithm [@Hornby-GECCO-2006;@Hornby-GECCO-2009-ALPSsteady] for age-layering several optimization runs together.  The layers interface is based on migration of younger individuals in the population into older layers.  If the individual is too old, and does not dominate another individual in its next layer, it is removed from the population.  Age layering can be disabled through the use of a single layer if desired.\n",
    "* Latin hypercube sampling to generate the initial population of individuals in the population.\n",
    "* A generic architecture for evolving the layered population(s).  In the current version, differential evolution [@Storn-JGO-1997] is the default evolving method, though an extensible API is available that allows for plug-and-play of alternative population evolution methods.  Flags for the evolver are handled in a generic way with a JavaScript Object Notation (JSON) structure.\n",
    "* Use of native C++11 threads (with a thread pool) to parallelize the evaluation of the cost function, allowing for a nearly-linear speedup as more computational cores are made available.\n",
    "* Ability to log all inputs and outputs (along with an optional filtering function) for further analysis of the progress of the optimization.\n",
    "* A single-threaded Python wrapper (``PyCEGO``) is written with ``pybind11``^[https://github.com/pybind/pybind11] and is used to demonstrate the functionality of the library, though it cannot fully leverage the parallelism available in CEGO at the C++ level.\n",
    "\n",
    "A few ``Jupyter`` notebooks [@ipython;@Kluyver:2016aa] are provided as examples that implement:\n",
    "\n",
    "A) optimization of cost functions of two- and ten-dimensional continuous variables.\n",
    "B) the mixed-integer nonlinear optimization problems of the constrained optimization of a pressure vessel mass and dimensionally-constrained spring [@Sandgren-JMD-1990]\n",
    "C) inverse modeling of Gaussian bumps.  \n",
    "\n",
    "All global optimization problems successfully obtain the minimum value from the literature, or better.  Furthermore, a ``binder`` [@jupyter2018binder] environment has been configured such that the Jupyter notebooks can be run interactively in an internet browser without any installation on the user's computer.\n",
    "\n",
    "An example is given here of the global optimization of the modified hundred-digit optimization problem [@Townsend-THESIS, Eq. 5.15], a function with 9,318 different local minima in $[-1,1] \\times [-1,1]$.  CEGO finds the correct global minimum value of âˆ’3.398166873463248.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.system(\"python setup.py install\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import exp, sin\n",
    "import PyCEGO\n",
    "\n",
    "def HundredDigitPlus(c):\n",
    "    \"\"\" The cost function to be minimized \"\"\"\n",
    "    x, y = c\n",
    "    if isinstance(x, PyCEGO.Numberish):\n",
    "        x = x.as_double()\n",
    "        y = y.as_double()\n",
    "    return (0.25*x**2 + exp(sin(100*x)) + sin(140*sin(x))\n",
    "            + 0.25*y**2 + sin(120*exp(y)) + sin(sin(160*y)) - sin(20*(x+y)))\n",
    "\n",
    "D = 2\n",
    "layers = PyCEGO.NumberishLayers(HundredDigitPlus, D, D*20, 1, 3)\n",
    "layers.set_bounds([PyCEGO.Bound(-1.0, 1.0) for _ in range(D)])\n",
    "layers.set_builtin_evolver(PyCEGO.BuiltinEvolvers.differential_evolution)\n",
    "\n",
    "VTR = -4 # Value to reach as acceptable optimization run\n",
    "for counter in range(1000):\n",
    "    layers.do_generation()\n",
    "    cost, coeffs = layers.get_best()\n",
    "    if counter % 50 == 0:\n",
    "        print(layers.print_diagnostics())\n",
    "    if cost < VTR:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "with the output\n",
    "\n",
    "i: 0 best: -1.81873 c: -0.688891, -0.796059,  queue: 0\n",
    "i: 50 best: -2.92206 c: -0.588456, 0.030352,  queue: 0\n",
    "i: 100 best: -3.06838 c: 0.169587, -0.408309,  queue: 0\n",
    "i: 150 best: -3.3345 c: 0.169926, -0.400595,  queue: 0\n",
    "i: 200 best: -3.36308 c: -0.145131, -0.404304,  queue: 0\n",
    "i: 250 best: -3.39762 c: 0.169466, -0.402987,  queue: 0\n",
    "i: 300 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 350 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 400 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 450 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 500 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 550 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 600 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 650 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 700 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 750 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 800 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 850 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 900 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "i: 950 best: -3.39817 c: 0.169674, -0.403046,  queue: 0\n",
    "\n",
    "# Disclaimer\n",
    "\n",
    "Contribution of the National Institute of Standards and Technology, not subject to copyright in the U.S.  Trade names are provided only to specify procedures adequately and do not imply endorsement by the National Institute of Standards and Technology. Similar products by other manufacturers may be found to work as well or better.\n",
    "\n",
    "# References\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
